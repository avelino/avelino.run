{
  "title" : "Developer Resistance to AI in Programming: Psychology and Data",
  "date" : "2025-11-16T00:00:00+00:00",
  "tags" : [ ],
  "url" : "https://avelino.run/developer-resistance-ai-programming-psychology-data",
  "content" : "In recent years, AI tools based on LLMs (large language models) have become widely available to assist with programming. Platforms like GitHub Copilot and ChatGPT promise to autocomplete code, suggest solutions, and boost developer productivity. Even with all this potential, many developers show resistance or hesitation when it comes to adopting these tools in their daily work.\n\nThis blog post explores why that happens, bringing together recent data on AI adoption and psychological aspects that help explain this reluctance. We'll also discuss how AI can be a powerful ally for developers – as long as it's used with discernment and a solid understanding of the business context (which only humans actually have).\n\nThe Rise of AI Coding Tools\n\nThe adoption of AI coding assistants has grown rapidly. According to a Google DORA report (2025), 90% of technology professionals already use AI in their workflows, a jump of 14% compared to the previous year (source: observer.com). These assistants are used for tasks ranging from writing code snippets to executing tests and performing security reviews (observer.com). Leading companies are investing heavily in this space – and in fact, 85% of developers say AI has made them more productive, although 41% say the improvement was only slight (observer.com).\n\nDespite the initial optimism, it's not all sunshine and rainbows. Trust in AI tools has not grown at the same pace as adoption. Only 24% of developers say they trust AI-generated code a lot, while almost a third admit they trust it very little or not at all (observer.com). Other surveys confirm this caution: more developers distrust AI accuracy (46%) than trust it (33%), and only a small fraction (~3%) report full confidence in the assistant's responses (survey.stackoverflow.co).\n\nIn other words, AI has entered the workflow, but with one foot out the door. Many developers see it as an assistant, not a partner, as a Google Cloud research lead put it (observer.com). This paradox – high availability of AI versus low trust – sets the stage for understanding where the resistance comes from.\n\nResistance to Change Is Real\n\nIt's no surprise there's hesitation. Resisting change in the workplace is a very common human reaction, especially when it involves disruptive innovation. With the new wave of AI tools, this shows up as lower-than-expected adoption and shy usage of more advanced features.\n\nFor example, a large study with 28,698 software engineers showed that only 41% used an AI coding assistant in the first year after it was introduced, even with organizational encouragement (papers.ssrn.com). In certain groups, adoption was even lower – only 31% of women engineers and 39% of developers over 40 used the tool at all (papers.ssrn.com). These numbers illustrate how strong the cultural and psychological barrier to adoption can be, even when the technology is already there.\n\nFrom an organizational standpoint, three out of four companies report that the hardest part of implementing AI is getting people to change how they work (bain.com). Under pressure or tight deadlines, many developers fall back to old habits instead of using the new tool (bain.com). This resistance doesn't mean stubbornness for no reason – there are usually legitimate concerns underneath it.\n\nNext, we'll look at the main psychological factors that make developers wary of relying on AI.\n\nWhy Are Developers Afraid? (Psychological Factors)\n\nFear of Losing Their Job or Relevance\n\nA latent concern is that AI might make developers obsolete. Almost half of professionals (49%) fear that automation will replace their role in the next five years (about.gitlab.com). This fear of substitution can drive resistance: some people avoid adopting the tool so they don't train their own replacement.\n\nOn top of that, some worry that using AI could undermine their importance on the team – after all, if anyone with AI can produce code, where does that leave the value of the human specialist? Research points exactly to this: some engineers are concerned that AI hurts their role within the team (bain.com). This sense of vulnerability in their job is a powerful reason to keep AI at arm's length.\n\nFear of Appearing Less Competent\n\nDevelopers tend to be proud of their ability to solve complex problems. Admitting they need help from an AI can sound, to some, like a sign of lack of competence.\n\nA recent academic study describes this as a competence penalty: in an experiment, engineers who used AI to help write code received competence ratings 9% lower (for the exact same output) compared to those who did not use AI – and women were penalized even more heavily (papers.ssrn.com).\n\nIn other words, there is a perception (and sometimes a reality) that those who rely on AI are seen as less capable. Many developers anticipate this stigma and therefore avoid using the tool to protect their professional reputation (papers.ssrn.com). Put simply, ego and identity are on the line: If I don't write every line myself, am I less of a developer? That mindset can drag adoption down, especially in cultures that glorify the lone hero who codes everything by hand.\n\nDistrust in the Accuracy and Quality of AI-Generated Code\n\nProgrammers are naturally skeptical – finding errors and bugs is literally part of the job. With AI, it's no different. There is a trust deficit when it comes to AI-generated answers.\n\nAs mentioned earlier, the majority do not fully trust AI-suggested code (only ~3% trust it blindly) (survey.stackoverflow.co). More experienced developers are the most cautious group, with the highest rate of no trust at all (20%) among experience levels (survey.stackoverflow.co).\n\nThis caution is justified: AI models often provide solutions that are almost correct, but not quite, which can introduce subtle errors and require extra debugging later (arstechnica.com). Many developers report frustration when AI hallucinates incorrect code or provides context-free suggestions – for example, a generic solution that simply doesn't apply to the specific case at hand.\n\nEach failure reduces trust and reinforces the idea that it's safer to rely on your own knowledge. If you're going to review every line of AI-generated code in detail, some developers prefer to write everything from scratch.\n\nAttachment to Control and Comfort Zone\n\nSoftware development is not just a technical activity – it's also a craft of authorship and control. Handing part of that control over to a machine can feel uncomfortable.\n\nMany developers are proud of understanding every line of code they write; with AI generating entire blocks, there is a real fear of becoming a passive operator. Unsurprisingly, most people see AI as just an assistant that suggests things, and hesitate to hand over the wheel completely (observer.com).\n\nThere's also the habit factor: years of experience shape personal workflows. Under pressure, professionals usually choose what they already know – even if the new tool might theoretically be better (bain.com). Learning to use AI effectively (writing good prompts, interpreting and debugging its output) takes time and a mindset shift. Without proper training, the novelty can feel more like an obstacle than a help. In fact, companies note that AI skill gaps (for example, knowing how to review AI-generated code) contribute to AI being used far below its potential (bain.com).\n\nIn short, changing habits is hard – and in everyday work, many people prefer to stick with familiar tools and methods, where they feel in control.\n\nAI as an Ally: Balancing Productivity and Caution\n\nDespite all the resistance, it's important to highlight that those who manage to integrate AI into their work see real, tangible benefits.\n\nStudies show 10–15% productivity gains in teams that adopt coding assistants, even when you factor in some amount of rework (bain.com). AI tools can automate repetitive tasks, suggest standardized solutions, and even help generate tests, freeing developers to focus on more creative or higher-level challenges. It's no coincidence that organizations that embrace AI strategically are shipping software faster and more reliably (observer.com).\n\nA leadership guideline from DX sums it up well:\n\n> Developers who leverage AI will outperform those who resist adoption.\n\n(getdx.com)\n\nIn other words, there is a real opportunity cost in ignoring these tools – in the long run, those who learn to use them well will be able to deliver more value.\n\nHowever, embracing AI doesn't mean doing it blindly. The key is to balance machine efficiency with human expertise.\n\nNo AI knows:\n\n- the domain of your business\n- the specific rules of your application\n- the exact needs of your users\n\nThe people who have that knowledge are developers and product teams.\n\nAs one researcher put it, AI is only as good as the data it has access to. If we don't provide proper context, it will give generic and potentially useless answers (observer.com).\n\nIt's up to the developer to provide the right instructions and, above all, critically validate the result before shipping anything. AI tools still make logical mistakes and do not truly understand business intent on their own – they should not be treated as infallible oracles, but as an incredibly fast (and sometimes clumsy) pair programmer.\n\nPractically speaking, this means:\n\n- reviewing each generated snippet\n- writing and running tests\n- adjusting details as needed\n\nThe best teams are integrating AI with good engineering practices: code reviews focused on checking whether the AI suggestion really does what it should, automated tests to catch regressions, and clear policies on where it's acceptable to rely on AI-generated code (for example, maybe fine for an internal script, but not for a critical module without human audit) (bain.com).\n\nConclusion: Conscious Adaptation\n\nThe arrival of AI in software development brings a mix of excitement and anxiety. We've seen that many developers resist it out of fear of losing space, protecting their reputation, or simply technical caution – and these concerns are valid.\n\nOn the other hand, completely ignoring AI can mean falling behind in productivity and professional growth. The ideal path lies in the middle ground: adopting these tools as allies, without giving up critical thinking.\n\nRemember: responsibility for the shipped code is still ours. As professionals, we need to understand and own what we deliver to users – and no AI is going to change that.\n\nInstead of seeing AI as a competitor, it's far more productive to view it as an extension of our capabilities. It helps us write code, but it cannot replace our understanding of the problem or our creativity in solving it. While AI takes care of the boilerplate, it's up to us to ensure the final product respects business rules, is secure, and is high quality.\n\nThose who learn to use these tools with discernment will get the best of both worlds: speed and quality. In short, AI can help us a lot – as long as we never give up understanding what we're delivering.\n\nAfter all, the ones who truly know the terrain (and see the bigger picture) are humans, not machines. With an adjusted mindset (less fear, more openness) and solid engineering practices, we can embrace innovation without losing control of the steering wheel.\n\nThe result is a developer who is more productive and more valuable – exactly because they know how to leverage new tools without compromising technical excellence.\n\nSources\n\n- Gai, Phyliss et al. Competence Penalty Is a Barrier to the Adoption of New Technology. SSRN, 2025. https://papers.ssrn.com\n- Stack Overflow. 2025 Developer Survey – AI. Stack Overflow Surveys. https://survey.stackoverflow.co\n- Dey, Victor. Google Study Shows A.I. Writes Code, But Developers Still Don't Fully Trust It. Observer, Sep. 2025. https://observer.com\n- Acar, Oguz et al. Research: The Hidden Penalty of Using AI at Work. Harvard Business Review, Aug. 2025. https://hbr.org\n- Salvador, Emilio. 6 strategies to help developers accelerate AI adoption. GitLab Blog, Oct. 2024. https://about.gitlab.com\n- From Pilots to Payoff: Generative AI in Software Development. Bain & Company Tech Report, 2025. https://bain.com\n- AI Code Generation: Best Practices for Enterprise Adoption in 2025. DX Blog, 2025. https://getdx.com\n- Stokel-Walker, Chris. Trust in AI coding tools is plummeting. LeadDev, Jul. 2025. https://arstechnica.com",
  "type" : "blog",
  "file-path" : "content/blog/2025-11-developer-resistance-ai-programming-psychology-data.md"
}