{
  "title" : "Configurando limite de recursos em aplica√ß√µes Java (JVM) no Kubernetes",
  "date" : "2021-05-01T00:00:00+00:00",
  "tags" : [ ],
  "url" : "https://avelino.run/configurando-limite-de-recursos-em-aplicacoes-java-jvm-no-kubernetes",
  "content" : "Fazer deploy de software desenvolvido usando tecnologias que foram criadas para ter escalabilidade vertical para escalar horizontalmente (_micro servi√ßo, nano servi√ßo_ e etc) em produ√ß√£o pode gerar alguns desafios que n√£o estamos preparados. Principalmente quando o software esta rodando em JVM e n√£o foi declarado limites de recursos.\n\n-Xms, -Xmx e seus problemas\n\nAo estudar sobre a JVM voc√™ provavelmente passara pelos par√¢metros de aloca√ß√£o inicial (Xms) e aloca√ß√£o m√°xima (Xmx) de mem√≥ria, os par√¢metros funcionam rigorosamente bem. Trazendo um exemplo, ao definir -Xms128M e Xmx256M, e come√ßar monitorar a aplica√ß√£o com VisualVM, voc√™ alguma como essa:\n\n\n\n``shell\njava -Xms128m -Xmx256m hello.java\n`\n\nAo ler a documenta√ß√£o da JVM (a parte de Sizing the Generations) parece que funcionara como magica, no exemplo acima a aplica√ß√£o querer m√≠nimo de 128Mb de mem√≥ria (JVM alocar√° assim que a aplica√ß√£o iniciar), mas n√£o deixando passar do limite de 256Mb. Vamos dar uma olhada como ficou na pr√°tica:\n\n\n\n`java\npublic class Hello {\n    public static void main(String[] args) throws Exception {\n        while (true) {\n            new Hello().hello();\n            Thread.sleep(1000);\n        }\n    }\n\n    public void hello() {\n        System.out.println(Hello, World);\n    }\n}\n`\n\nüò± n√£o saiu como eu imaginava, parece que usou um pouco mais que 256Mb... O motivo desse comportamento √© que a JVM usa mem√≥ria para outros processos como metaspace, cache de c√≥digo e etc, o Xmx limita s√≥ sua aplica√ß√£o n√£o a JVM como todo.\n\nAlguns cuidados que precisamos ter ao limitar recursos\n\nAo rodar software dentro do Kubernetes, temos que ter aten√ß√£o no limite f√≠sico das m√°quinas que fazem parte do Cluster Kubernetes, para um pod n√£o consumir todo recurso e outros pods acabar _morrendo_.\n\nVou testar exemplificar...\n\nConfigurando Xms e Xmx na imagem Docker\n\nVoc√™ pode passar estas flags (par√¢metros) para JVM subir seu JAR na imagem Docker:\n\n`dockerfile\nDockerfile\n...\nENTRYPOINT [java, -Xms128M , -Xmx256m, -jar, hello-service-1.0.0.jar]\n`\n\nCaso esteja usando Jib, pode declarar dentro do build.gradle:\n\n`gradle\n// build.gradle\njib {\n    to {\n        image = hello-service:tag\n    }\n    container {\n        environment = [JAVA_TOOL_OPTIONS: -Xms128M -Xmx256M]\n    }\n}\n`\n\nLimitando mem√≥ria dos pods no Kubernetes\n\nAo usar Xmx no pods voc√™ pode facilmente chegar em uma configura√ß√£o que causar√° restart contante, por motivos de _Exceed a Container's memory limit (OOM)_\n, por motivos a limite de mem√≥ria, lembre do printscreen acima que mesmo limitando a aplica√ß√£o a 256Mb a JVM usou mais de 700Mb. Dependendo do seu software deve ser definido o limite de recurso no pr√≥prio Kubernetes no YAML do seu deployment:\n\n`yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n...\nspec:\n  ...\n  template:\n    ...\n    spec:\n      containers:\n        - image: hello-service:tag\n          name: hello-service\n          livenessProbe:\n            initialDelaySeconds: 300\n          resources:\n            requests:\n              memory: 128Mi\n            limits:\n              memory: 256Mi\n`\n\nVou assumir que voc√™ declarou os limites acima para seus pods, j√° que voc√™ tamb√©m declarou os mesmos limites na sua imagem Docker via flags -Xms e  -Xmx. Voc√™ faz deploy do seu software, ele funciona _perfeitamente_, como n√£o teve problema vai para cama descansar (geralmente colocar software em produ√ß√£o √© cansativo). No dia seguinte voc√™ da roda kubectl get pods para ter orgulho de ter colocado seu software no ~~Kubernetes~~ e se depara com isso:\n\n`shell\n‚ùØ ~ kubectl get pods\nNAME                              READY   STATUS    RESTARTS   AGE\nhello-service-3x85997760-qapo7     1/1     Running   156        9h\n`\n\nüí£ voc√™ n√£o esperava ver isso n√©? Agora que conhece como funciona a JVM (com printscren do htop) voc√™ j√° sabe o que esta acontecendo: o uso de mem√≥ria da JVM n√£o √© s√≥ do seu software, ent√£o ele √© morto diversas vezes (campo RESTARTS do get pods) porqu√™ o pod passou do limite de mem√≥ria declarado e entra em um fluxo sem fim de _restart_.\n\nAbordagem correta\n\nPrimeiro de tudo: assumiremos que os limites dentro da sua imagem Docker estejam bem definidos - com o que o software realmente precisa. Caso voc√™ queira reservar um valor fixo de mem√≥ria para seu software e n√£o ter concorr√™ncia com outro, voc√™ deve declarar Xms = Xmx, mas _use com modera√ß√£o_.\n\nPara evitar _Exceed a Container's memory limit_ no pods do Kubernetes, voc√™ deve considerar os seguintes itens:\n\n1. requests (par√¢metro do resources) != Xms - o valor do requests deve ser maior que Xms, essa diferen√ßa depende do que seu software far√°. Caso seja um _micro servi√ßo_ simples, ~30% de acr√©scimo √© o suficiente, mas se seu software tem muitas conex√µes externas ou qualquer opera√ß√£o que consome mem√≥ria recomendo estudar a particularidade do seu software;\n2. limits (par√¢metro do resources) != Xmx - O limite de mem√≥ria sugerido para seu pod depende de muitas coisas e a imagem base do Java usada √© um fator extremamente importante. N√£o vou passar um valor nem f√≥rmula ~~magica~~, recomendo fazer diversos benchmarks para conhecer melhor o software que esta desenvolvendo;\n3. Declarar limits com valores mais alto no come√ßo √© sempre uma boa pr√°tica, mas ir otimizando (diminuindo ou aumentando) conforme for conhecendo o comportamento do seu software em produ√ß√£o, sempre monitorando se o pod n√£o entra em OOM;\n4. livenessProbe.initialDelaySeconds - Tempo que o Kubernetes deve esperar seu software subir (JVM) antes de dar que n√£o funcionou. Esse par√¢metro √© complicado, JVM tem fama de ser lenta para fazer boot, se seu software tem muitas conex√µes externas ela levar√° mais tempo.\n\nOlhando para o caso que foi descrito acima: declarar requests como ~320Mb e limits como ~512Mb seria um √≥timo come√ßo dado os valores do Xms e Xmx.\n\n> N√£o existe bala de prata, a melhor forma de chegar em valores reais para limites de recursos no Kubernetes √© conhecer seu software e fazer benchmarks para entender o comportamento dele, acada software √© √∫nico e se comporta de uma forma diferente.\n\n> Recentemente coloquei um micro servi√ßo usando Spring Boot para rodar e o servi√ßo n√£o subia, depois de horas e horas debugando e brigando com limite recurso do software e Kubernetes percebi que o problema era o initialDelaySeconds`. _#ficaadica_",
  "type" : "blog",
  "file-path" : "content/blog/configurando-limite-de-recursos-em-aplicacoes-java-jvm-no-kubernetes.md"
}