+++
date = "2021-05-01"
title = "Configurando limite de recursos em aplica√ß√µes Java (JVM) no Kubernetes"
tags = ["java", "jvm", "kubernetes", "heapsize", "permsize"]
url = "configurando-limite-de-recursos-em-aplicacoes-java-jvm-no-kubernetes"
images = ["/blog/jvm-xms-xmx-heapsize.png"]
+++

Fazer deploy de software desenvolvido usando tecnologias que foram criadas para ter escalabilidade vertical para escalar horizontalmente (_micro servi√ßo, nano servi√ßo_ e etc) em produ√ß√£o pode gerar alguns desafios que n√£o estamos preparados. Principalmente quando o software esta rodando em JVM e n√£o foi declarado limites de recursos.

> Blogpost escrito com experi√™ncia adquirida¬†no¬†[Soluevo](https://soluevo.com.br/) - desenvolvendo software para processar grande volume de dados.
> A _Soluevo_¬†tem vaga (**de j√∫nior a s√™nior**) para pessoal desenvolvedora que conhe√ßa e queira trabalhar com¬†**Java**, veja¬†[aqui as vagas](https://www.notion.so/soluevo/861ba87abf194a669eba94b8f47d8cbc?v=fd32972a433948ceaf0c2cf3223a3d42).

## `-Xms`, `-Xmx` e seus problemas

Ao estudar sobre a JVM voc√™ provavelmente passara pelos par√¢metros de aloca√ß√£o inicial (`Xms`) e aloca√ß√£o m√°xima (`Xmx`) de mem√≥ria, os par√¢metros funcionam rigorosamente bem. Trazendo um exemplo, ao definir `-Xms128M` e `Xmx256M`, e come√ßar monitorar a aplica√ß√£o com [VisualVM](https://visualvm.github.io/), voc√™ alguma como essa:

![VisualVM declarado Xms e Xmx na JVM](/blog/jvm-xms-xmx-heapsize.png#center)

```shell
java -Xms128m -Xmx256m hello.java
```

Ao ler a documenta√ß√£o da JVM (a parte de [Sizing the Generations](https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/sizing.html)) parece que funcionara como magica, no exemplo acima a aplica√ß√£o querer m√≠nimo de 128Mb de mem√≥ria (JVM alocar√° assim que a aplica√ß√£o iniciar), mas n√£o deixando passar do limite de 256Mb. Vamos dar uma olhada como ficou na pr√°tica:

![Usando Xms e -Xmx na JVM](/blog/jvm-htop-xms-xmx.png#center)

```java
public class Hello {
    public static void main(String[] args) throws Exception {
        while (true) {
            new Hello().hello();
            Thread.sleep(1000);
        }
    }

    public void hello() {
        System.out.println("Hello, World");
    }
}
```

üò± n√£o saiu como eu imaginava, parece que usou um pouco mais que 256Mb... O motivo desse comportamento √© que a **JVM usa mem√≥ria para outros processos** como metaspace, cache de c√≥digo e etc, o `Xmx` limita s√≥ sua aplica√ß√£o n√£o a JVM como todo.

## Alguns cuidados que precisamos ter ao limitar recursos

Ao rodar software dentro do Kubernetes, temos que ter aten√ß√£o no limite f√≠sico das m√°quinas que fazem parte do Cluster Kubernetes, para um pod n√£o consumir todo recurso e outros pods acabar _"morrendo"_.

Vou testar exemplificar...

### Configurando `Xms` e `Xmx` na imagem Docker

Voc√™ pode passar estas flags (par√¢metros) para JVM subir seu **JAR** na imagem Docker:

```dockerfile
# Dockerfile
# ...
ENTRYPOINT ["java", "-Xms128M ", "-Xmx256m", "-jar", "hello-service-1.0.0.jar"]
```

Caso esteja usando [**Jib**](https://github.com/GoogleContainerTools/jib), pode declarar dentro do `build.gradle`:

```gradle
// build.gradle
jib {
    to {
        image = "hello-service:tag"
    }
    container {
        environment = ["JAVA_TOOL_OPTIONS": "-Xms128M -Xmx256M"]
    }
}
```

### Limitando mem√≥ria dos pods no Kubernetes

Ao usar `Xmx` no pods voc√™ pode facilmente chegar em uma configura√ß√£o que causar√° restart contante, por motivos de [_Exceed a Container's memory limit (OOM)_
](https://kubernetes.io/docs/tasks/configure-pod-container/assign-memory-resource/#exceed-a-container-s-memory-limit), por motivos a limite de mem√≥ria, lembre do printscreen acima que mesmo limitando a aplica√ß√£o a **256Mb** a JVM usou mais de **700Mb**. Dependendo do seu software deve ser definido o limite de recurso no pr√≥prio Kubernetes no `YAML` do seu deployment:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
# ...
spec:
  # ...
  template:
    # ...
    spec:
      containers:
        - image: hello-service:tag
          name: hello-service
          livenessProbe:
            initialDelaySeconds: 300
          resources:
            requests:
              memory: 128Mi
            limits:
              memory: 256Mi
```

Vou assumir que voc√™ declarou os limites acima para seus pods, j√° que voc√™ tamb√©m declarou os mesmos limites na sua imagem Docker via flags `-Xms` e  `-Xmx`. Voc√™ faz deploy do seu software, ele funciona _"perfeitamente"_, como n√£o teve problema vai para cama descansar (geralmente colocar software em produ√ß√£o √© cansativo). No dia seguinte voc√™ da roda `kubectl get pods` para ter orgulho de ter colocado seu software no ~~Kubernetes~~ e se depara com isso:

```shell
‚ùØ ~ kubectl get pods
NAME                              READY   STATUS    RESTARTS   AGE
hello-service-3x85997760-qapo7     1/1     Running   156        9h
```

üí£ voc√™ n√£o esperava ver isso n√©? Agora que conhece como funciona a JVM (com printscren do htop) voc√™ j√° sabe o que esta acontecendo: o uso de mem√≥ria da JVM n√£o √© s√≥ do seu software, ent√£o ele √© morto diversas vezes (campo RESTARTS do `get pods`) porqu√™ o pod passou do limite de mem√≥ria declarado e entra em um fluxo sem fim de _restart_.

## Abordagem correta

Primeiro de tudo: assumiremos que os limites dentro da sua imagem Docker estejam bem definidos - com o que o software realmente precisa. Caso voc√™ queira reservar um valor fixo de mem√≥ria para seu software e n√£o ter concorr√™ncia com outro, voc√™ deve declarar `Xms` = `Xmx`, mas _use com modera√ß√£o_.

Para evitar _Exceed a Container's memory limit_ no pods do Kubernetes, voc√™ deve considerar os seguintes itens:

1. `requests` (par√¢metro do `resources`) != `Xms` - o valor do `requests` deve ser maior que `Xms`, essa diferen√ßa depende do que seu software far√°. Caso seja um _micro servi√ßo_ "simples", ~30% de acr√©scimo √© o suficiente, mas se seu software tem muitas conex√µes externas ou qualquer opera√ß√£o que consome mem√≥ria recomendo estudar a particularidade do seu software;
2. `limits` (par√¢metro do `resources`) != `Xmx` - O limite de mem√≥ria sugerido para seu pod depende de muitas coisas e a imagem base do Java usada √© um fator extremamente importante. N√£o vou passar um valor nem f√≥rmula ~~magica~~, recomendo fazer **diversos benchmarks para conhecer melhor o software que esta desenvolvendo**;
3. Declarar `limits` com valores mais alto no come√ßo √© sempre uma boa pr√°tica, mas ir otimizando (diminuindo ou aumentando) conforme for conhecendo o comportamento do seu software em produ√ß√£o, sempre monitorando se o pod n√£o entra em OOM;
4. `livenessProbe.initialDelaySeconds` - Tempo que o Kubernetes deve esperar seu software subir (JVM) antes de dar que n√£o funcionou. Esse par√¢metro √© complicado, JVM tem fama de ser "lenta" para fazer boot, se seu software tem muitas conex√µes externas ela levar√° mais tempo.

Olhando para o caso que foi descrito acima: declarar `requests` como ~320Mb e `limits` como ~512Mb seria um √≥timo come√ßo dado os valores do `Xms` e `Xmx`.

> **N√£o existe bala de prata**, a melhor forma de chegar em valores reais para limites de recursos no Kubernetes √© conhecer seu software e fazer **benchmarks** para entender o comportamento dele, acada software √© √∫nico e se comporta de uma forma diferente.

> Recentemente coloquei um micro servi√ßo usando [Spring Boot](https://spring.io/projects/spring-boot) para rodar e o servi√ßo n√£o subia, depois de horas e horas debugando e "brigando" com limite recurso do software e Kubernetes percebi que o problema era o `initialDelaySeconds`. _#ficaadica_
